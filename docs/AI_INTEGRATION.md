# Nexscholar AI Integration Guide

This document provides a deep dive into the AI-powered functionalities of the Nexscholar platform. It covers the architecture, data flows, and technical implementation of features like semantic search, AI matching, and automated profile creation.

## Table of Contents

- [AI Services Overview](#ai-services-overview)
- [Core Technologies](#core-technologies)
- [Part 1: Embedding Generation & Storage](#part-1-embedding-generation--storage)
  - [The Embedding Pipeline](#the-embedding-pipeline)
  - [Text Preparation Strategy](#text-preparation-strategy)
  - [Artisan Commands for Generation](#artisan-commands-for-generation)
  - [Qdrant Vector Database](#qdrant-vector-database)
- [Part 2: Semantic Search & AI Matching](#part-2-semantic-search--ai-matching)
  - [Search Workflow](#search-workflow)
  - [Hybrid Scoring](#hybrid-scoring)
  - [AI-Generated Insights (GPT-4o)](#ai-generated-insights-gpt-4o)
- [Part 3: AI Profile Generation](#part-3-ai-profile-generation)
  - [Generation Methods](#generation-methods)
  - [The Generation Process](#the-generation-process)
- [Part 4: Postgraduate Program Recommendations](#part-4-postgraduate-program-recommendations)
- [Key Services & Controllers](#key-services--controllers)

---

## AI Services Overview

Nexscholar's AI integration is designed to automate and enhance the academic networking experience. The features can be grouped into two main categories:

1.  **Understanding & Matching**: Using vector embeddings to understand the semantic meaning of users' research interests and intelligently match them with relevant people or opportunities.
2.  **Content Generation & Automation**: Using Large Language Models (LLMs) like GPT-4o to automate the creation of user profiles and provide personalized, context-aware explanations.

## Core Technologies

-   **OpenAI API**:
    -   **`text-embedding-3-small`**: The model used to convert text data (user profiles, search queries) into 1536-dimension numerical vectors (embeddings). This is the foundation of all semantic search features.
    -   **`gpt-4o`**: The model used for all generative tasks, such as creating profile summaries from a CV or writing personalized insights for an AI match.
-   **Qdrant**: A high-performance vector database used to store, index, and search the millions of vectors generated by the OpenAI embedding model.
-   **Laravel Queues**: All AI-related operations (embedding generation, API calls to OpenAI, scraping) are processed asynchronously as background jobs to ensure the user interface remains fast and responsive.

## Part 1: Embedding Generation & Storage

Before any semantic search can occur, the profiles of users and other entities (like postgraduate programs) must be converted into embeddings and stored in Qdrant.

### The Embedding Pipeline

1.  **Trigger**: An administrator runs an Artisan command (e.g., `php artisan embeddings:generate-academician`).
2.  **Data Fetching**: The command queries the primary database for the target records (e.g., all academicians with complete profiles).
3.  **Text Preparation**: For each record, the `EmbeddingService` constructs a detailed, structured text string that comprehensively describes that person or item.
4.  **API Call**: The prepared text is sent to the OpenAI `text-embedding-3-small` model via an API call.
5.  **Store in Qdrant**: The returned 1536-dimension vector is stored in the appropriate Qdrant collection, along with metadata.

### Text Preparation Strategy

The quality of the semantic search is highly dependent on the quality of the text used to generate the embeddings. Instead of simply using a raw bio, Nexscholar employs a structured approach to create a rich text document for each user.

-   **Hierarchical Skills Integration**: The system now incorporates the 3-level skills taxonomy (Domain → Subdomain → Skill) into the embedding generation process. Skills are loaded with full relationships using `$user->skills()->with('subdomain.domain')->get()` to access the complete hierarchy.
-   **Skills Text Construction**: Each skill contributes to the embedding text in multiple formats:
    -   Full hierarchy: "Technology & Information Technology → Software Development → React.js"
    -   Individual components: "Technology", "Software Development", "React.js"
    -   Skill categories: "Programming Languages", "Web Frameworks", etc.
-   **Hierarchical Research Fields**: The system resolves the stored research field IDs (e.g., `"1-5-12"`) into their full text names ("Computer Science - Artificial Intelligence - Natural Language Processing").
-   **Multiple Representations**: It creates several variations of this text to improve matching flexibility (e.g., "Fields: Computer Science", "Areas: Artificial Intelligence", "Computer Science Artificial Intelligence").
-   **Comprehensive Concatenation**: The structured research text is combined with hierarchical skills, position, department, and biography. This complete document provides rich semantic context for more accurate matching.

This enhanced strategy produces more consistent and meaningful embeddings by leveraging both the traditional research field structure and the new hierarchical skills taxonomy.

### Artisan Commands for Generation

-   `php artisan embeddings:generate-academician`: Generates embeddings for academicians.
-   `php artisan embeddings:generate-student`: Generates for postgraduates and/or undergraduates.
-   `php artisan embeddings:generate-postgraduate-programs`: Generates for postgraduate programs.
-   **Common Options**:
    -   `--force`: Regenerate embeddings even if they already exist.
    -   `--batch-size=20`: Process records in chunks to manage memory usage.
    -   `{id}`: Process only a single record by its ID.

### Qdrant Vector Database

-   **Collections**: Separate collections are used for different types of records (e.g., `nexscholar_academicians`, `nexscholar_students`).
-   **Payload Schema**: Each vector point in Qdrant is stored with a metadata "payload" that allows for filtering and identification. The schema is standardized and includes:
    -   `unique_id`: The human-readable ID (e.g., "ACAD-123").
    -   `user_id`: The primary `users.id`.
    -   `mysql_id`: The ID from the source table (e.g., `academicians.id`).
    -   `record_type`: The entity type ("academician", "student", etc.).
    -   `skills_metadata`: Additional metadata about the hierarchical skills for enhanced filtering and relevance scoring.
-   **Setup**: The collections can be created and configured using the `php artisan qdrant:setup` command.

## Part 2: Semantic Search & AI Matching

This is the user-facing application of the embedding pipeline.

### Search Workflow

1.  **User Query**: A user enters a natural language query in the AI Matching interface (e.g., "I'm looking for a supervisor in computational linguistics").
2.  **Query Embedding**: The `AIMatchingController` takes this query, enhances it with academic context, and sends it to the OpenAI API to be converted into an embedding.
3.  **Qdrant Search**: The `QdrantService` performs a similarity search in the relevant Qdrant collection using the query embedding. It returns a list of the top N most similar vectors (the best matches).
4.  **Hydrate Results**: The system uses the metadata from the Qdrant results to retrieve the full profile data for the matched users from the primary MySQL database.
5.  **Display Results**: The matched profiles are displayed to the user.

### Hybrid Scoring

To provide the most relevant results, the system uses a hybrid scoring model that considers both the user's explicit query and their own profile information.

-   **Weighting**: The final relevance score for a match is a weighted average:
    -   **60%**: Similarity between the search **query** and the potential match's profile.
    -   **40%**: Similarity between the searching **user's own profile** and the potential match's profile.
-   **Benefit**: This means that even if a student uses a vague query, the system can still provide highly personalized results by leveraging the detailed research interests in their own completed profile.

### AI-Generated Insights (GPT-4o)

To add a layer of explainability, the system uses GPT-4o to justify *why* a match was made.

1.  **Trigger**: After the top matches are retrieved from Qdrant, the frontend makes a separate request for "insights" for each match.
2.  **Context Assembly**: The `AIMatchingController` assembles a detailed prompt for the GPT-4o model. This prompt includes:
    -   The student's original search query.
    -   The student's own profile data (research interests, bio, hierarchical skills).
    -   The matched supervisor's profile data including their hierarchical skills structure.
    -   Crucially, a list of the supervisor's most relevant **publications** from their integrated Google Scholar data.
    -   Skills alignment analysis showing matching domains, subdomains, and specific skills.
3.  **API Call**: The prompt is sent to GPT-4o.
4.  **Response**: The model returns a concise, personalized paragraph explaining the synergy between the student and the supervisor, often referencing specific shared research interests or relevant publications.
5.  **Caching**: To reduce API costs and improve performance, these generated insights are cached for 30 minutes.

## Part 3: AI Profile Generation

This feature automates the tedious process of filling out a detailed academic profile.

### Generation Methods

1.  **CV-Based**: The system extracts text from an uploaded CV (PDF, DOCX). It uses direct text extraction where possible, with Tesseract OCR as a fallback for image-based documents.
2.  **URL-Based**: The system scrapes content from URLs provided by the user (e.g., institutional page, LinkedIn profile).
3.  **Automatic Search**: The system uses the Google Custom Search API to find academic information about the user, which is then used as the source material.

### The Generation Process

1.  **Initiation**: The user selects a method in the `AIProfileGeneration` React component. The request is sent to `RoleProfileController`.
2.  **Dispatch Job**: The controller dispatches a background job (e.g., `GenerateProfileFromCV`) to the queue. This immediately returns a response to the user so the UI is not blocked.
3.  **Background Processing**: The job performs the heavy lifting:
    -   It extracts or scrapes the source text.
    -   It constructs a detailed prompt for GPT-4o, instructing it to act as an academic assistant and extract specific, structured information (e.g., "list of degrees", "summary of research expertise", "professional biography").
    -   It sends the text and prompt to the OpenAI API.
4.  **Parsing & Caching**: The job parses the JSON response from the AI and stores the structured data in the cache, keyed by a unique job ID.
5.  **Frontend Polling**: The React component periodically polls a status endpoint (`/ai/status`). Once the job is complete, the frontend retrieves the generated data from the cache and populates the profile form fields for the user to review and save.

## Part 4: Postgraduate Program Recommendations

This feature adapts the core AI matching technology to help students find suitable academic programs.

-   **Workflow**:
    1.  A user (student or academician) uploads a CV and provides a text description of research interests.
    2.  This input is converted into an embedding.
    3.  A similarity search is performed against the `postgraduate_programs` collection in Qdrant.
    4.  The top matching programs are retrieved.
    5.  GPT-4o is used to generate a detailed justification for why each program is a good fit, based on the user's input and the program's description.
-   **Role-Aware Logic**: The system is designed to differentiate between a student searching for themselves and an academician searching for one of their students. When an academician uses the tool, the uploaded CV is stored separately and does *not* modify the academician's own profile.

## Key Services & Controllers

-   `AIMatchingController.php`: The main entry point for all semantic search and matching requests.
-   `RoleProfileController.php`: Handles the initiation of AI profile generation.
-   `PostgraduateRecommendationController.php`: Manages the program recommendation feature.
-   `app/Services/EmbeddingService.php`: Business logic for creating embeddings.
-   `app/Services/QdrantService.php`: A client for all interactions with the Qdrant database.
-   `app/Services/AIProfileService.php`: Contains the logic for generating profiles from different sources.
-   `app/Console/Commands/`: Contains all `artisan` commands for generating embeddings.
-   `app/Jobs/`: Contains all background jobs for AI processing.
